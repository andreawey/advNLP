{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MSE Logo](https://moodle.msengineering.ch/pluginfile.php/1/core_admin/logo/0x150/1643104191/logo-mse.png)\n",
    "\n",
    "# AdvNLP Lab (Graded Lab): Experimenting with Retrieval as Part of a RAG System\n",
    "\n",
    "Total: 44 points\n",
    "\n",
    "**Objectives:** We build the retrieval part of a RAG system and compare performance of classic KNN retrieval with additional cross encoder reranking. Eventually, we write two prompts for generation and test it on a LLM.\n",
    "\n",
    "**Useful documentation:** Since you'll use LangChain for this assignment, [their documentation](https://python.langchain.com/docs/introduction/) might be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "\n",
    "Dave Brunner, Andrea Wey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we need to install the required packages for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas langchain-community langchain-huggingface faiss-cpu --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain.retrievers import ContextualCompressionRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [DRAGONBall Dataset](https://github.com/OpenBMB/RAGEval) as a basis for this assignment and load a subset of their documents. These will be the stored knowledge of the RAG system. To store them into the vector store, we will later directly create embeddings out of them, since they have alredy the size of suitable chunks. Each document consists of a unique ID and the actual content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries= pd.read_csv('queries.csv', index_col=0)\n",
    "queries['ground_truth_doc_ids']= queries['ground_truth_doc_ids'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Acme Government Solutions is a government indu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Entertainment Enterprises Inc. is an entertain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Advanced Manufacturing Solutions Inc., establi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>EcoGuard Solutions, established on April 15, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Green Fields Agriculture Ltd., established on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Hospitalization Record:\\n\\nBasic Information:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>**Hospitalization Record**\\n\\n**Basic Informat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Hospitalization Record\\n\\nBasic Information:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Hospitalization Record\\n----------------------...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Hospitalization Record:\\n\\nBasic Information:\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content\n",
       "id                                                    \n",
       "40   Acme Government Solutions is a government indu...\n",
       "41   Entertainment Enterprises Inc. is an entertain...\n",
       "42   Advanced Manufacturing Solutions Inc., establi...\n",
       "43   EcoGuard Solutions, established on April 15, 2...\n",
       "44   Green Fields Agriculture Ltd., established on ...\n",
       "..                                                 ...\n",
       "211  Hospitalization Record:\\n\\nBasic Information:\\...\n",
       "212  **Hospitalization Record**\\n\\n**Basic Informat...\n",
       "213  Hospitalization Record\\n\\nBasic Information:\\n...\n",
       "214  Hospitalization Record\\n----------------------...\n",
       "215  Hospitalization Record:\\n\\nBasic Information:\\...\n",
       "\n",
       "[108 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = pd.read_csv('docs.csv', index_col=0)\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of the assignment is to evaluate the retrieval component of the RAG system. For that, we also load a dataset of queries, which we can use to retrieve matching documents. Each query has also assigned an array of documents in the form of their IDs, which match with the documents loaded before. We can use these to evaluate whether the correct documents were found by the retrieval or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>ground_truth_doc_ids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>When was Sparkling Clean Housekeeping Services...</td>\n",
       "      <td>[64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>How did HealthPro Innovations' strategic partn...</td>\n",
       "      <td>[54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>According to the hospitalization records of Br...</td>\n",
       "      <td>[212]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>According to the judgment of Norwood, Unionvil...</td>\n",
       "      <td>[124]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>Based on HealthLife Solutions' 2020 corporate ...</td>\n",
       "      <td>[73]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>How did the severe drought in August 2018 lead...</td>\n",
       "      <td>[65]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>Compare the large-scale financing activities o...</td>\n",
       "      <td>[58, 55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>How did CleanCo Housekeeping Services' investm...</td>\n",
       "      <td>[47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>What were the outcomes of the debt restructuri...</td>\n",
       "      <td>[56, 53]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>According to the hospitalization records of Wi...</td>\n",
       "      <td>[188, 213]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      query  \\\n",
       "query_id                                                      \n",
       "2286      When was Sparkling Clean Housekeeping Services...   \n",
       "2433      How did HealthPro Innovations' strategic partn...   \n",
       "6266      According to the hospitalization records of Br...   \n",
       "4499      According to the judgment of Norwood, Unionvil...   \n",
       "2448      Based on HealthLife Solutions' 2020 corporate ...   \n",
       "...                                                     ...   \n",
       "2186      How did the severe drought in August 2018 lead...   \n",
       "3251      Compare the large-scale financing activities o...   \n",
       "2268      How did CleanCo Housekeeping Services' investm...   \n",
       "3311      What were the outcomes of the debt restructuri...   \n",
       "6551      According to the hospitalization records of Wi...   \n",
       "\n",
       "         ground_truth_doc_ids  \n",
       "query_id                       \n",
       "2286                     [64]  \n",
       "2433                     [54]  \n",
       "6266                    [212]  \n",
       "4499                    [124]  \n",
       "2448                     [73]  \n",
       "...                       ...  \n",
       "2186                     [65]  \n",
       "3251                 [58, 55]  \n",
       "2268                     [47]  \n",
       "3311                 [56, 53]  \n",
       "6551               [188, 213]  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = pd.read_csv('queries.csv', index_col=0)\n",
    "queries['ground_truth_doc_ids'] = queries['ground_truth_doc_ids'].apply(lambda x: x.split(';'))\n",
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recall@N\n",
    "\n",
    "**1a) [2 points]** We will evaluate the retrieval by comparing the retrieved documents with the ground truth documents assigned to the query. For that, we will use the Recall@N metric. Please describe in 1-2 sentences how we can interpret this metric in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n",
    "The higher the recall, the more documents from the ground truth were found in the top N positions of the retrieved documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1b) [4 points]** Implement the Recall@N metric and test it with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_n(retrieved_docs, relevant_doc_ids, n):\n",
    "    \"\"\"\n",
    "    Calculate Recall@N.\n",
    "\n",
    "    Parameters:\n",
    "    - retrieved_docs: Sorted list of retrieved documents as LangChain Document objects\n",
    "    - relevant_doc_ids: List of relevant document IDs\n",
    "    - n: Number of top documents to consider\n",
    "\n",
    "    Returns:\n",
    "    - Recall@N\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the IDs of the top N retrieved documents\n",
    "    retrieved_doc_ids = [doc.metadata['id'] for doc in retrieved_docs[:n]]\n",
    "\n",
    "    # Calculate the number of relevant documents found in the top N\n",
    "    relevant_found = len(set(retrieved_doc_ids) & set(relevant_doc_ids))\n",
    "\n",
    "    # Calculate Recall@N\n",
    "    recall_at_n = relevant_found / len(relevant_doc_ids) if relevant_doc_ids else 0\n",
    "\n",
    "    return recall_at_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test\n",
    "\n",
    "recall_at_n(\n",
    "    [Document(page_content='', metadata={'id': str(id)}) for id in range(10)],\n",
    "    ['0', '1', '20'],\n",
    "    3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embedding Model\n",
    "\n",
    "**2a) [3 points]** Each document will be converted to an embedding representing the semantic meaning of the document. In this assignment, we will use model `sentence-transformers/all-MiniLM-L6-v2` from HuggingFace. Please answer the following questions about this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\Documents\\SUPSI\\NLP\\labs\\.advNLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 384\n",
      "Total parameters: 22713216\n",
      "Maximum sequence length: 256\n"
     ]
    }
   ],
   "source": [
    "# Load the embedding model\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-minilm-l6-v2')\n",
    "model = embeddings._client\n",
    "\n",
    "# what is the embedding length ?\n",
    "embedding_length = model.get_sentence_embedding_dimension()\n",
    "print(f\"Embedding length: {embedding_length}\")\n",
    "# number of parameters?\n",
    "total_params =[p.numel() for p in model.parameters()]\n",
    "print(f\"Total parameters: {sum(total_params)}\")\n",
    "\n",
    "# maximum sequence length?\n",
    "max_seq_length = model.get_max_seq_length()\n",
    "print(f\"Maximum sequence length: {max_seq_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answers:**\n",
    "\n",
    "Embedding Length: 384\n",
    "\n",
    "Number of Parameters: 22713216\n",
    "\n",
    "Maximum Sequence Length: 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vector Store\n",
    "\n",
    "**3a) [4 points]** Use LangChain to create a FAISS vector store and embed the documents with the above-mentioned embedding model. Load the documents again but this time with a Loader object from LangChain. Eventually, print the number of documents in the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 108 vectors in the vector store\n"
     ]
    }
   ],
   "source": [
    "# load the csv file\n",
    "loader = CSVLoader(file_path='docs.csv', metadata_columns=['id'])\n",
    "# create a FAISS vector store\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=loader.load(),\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(f\"there are {vector_store.index.ntotal} vectors in the vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b) [3 points]** Retrieve the Top-3 documents for this query: \"According to the hospitalization records of Bridgewater General Hospital, summarize the present illness of J. Reyes.\" and print the documents' ID and L2 distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: e1a873b3-e65b-44a0-a135-51bc5c29cdfa, L2 distance: 0.7137991786003113\n",
      "Document ID: 04361aed-6dee-40df-a5cf-667bf45174f9, L2 distance: 0.98215651512146\n",
      "Document ID: f1c38ba0-8dc6-4113-80c7-fe5eb3376761, L2 distance: 0.9883989691734314\n"
     ]
    }
   ],
   "source": [
    "# retrieve the top 3 documents for this query: \n",
    "query = \"According to the hospitalization records of Bridgewater General Hospital, summarize the present illness of J. Reyes\"\n",
    "retrieved_docs = vector_store.similarity_search_with_score(query, k=3, )\n",
    "# print the documentsID and L2 distance\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"Document ID: {doc[0].id}, L2 distance: {doc[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3c) [2 points]** Check and show if a suitable document is found for the query in the Top-3 retrieved documents and show the relevant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Document Found - ID: e1a873b3-e65b-44a0-a135-51bc5c29cdfa, L2 Distance: 0.7137991786003113\n",
      "Content: content: **Hospitalization Record**\n",
      "\n",
      "**Basic Information:**\n",
      "Name: J. Reyes\n",
      "Gender: Male\n",
      "Age: 52\n",
      "Ethnicity: Hispanic\n",
      "Marital Status: Married\n",
      "Occupation: Construction Worker\n",
      "Address: 22, Sunnyvale street, Bridgewater\n",
      "Admission Time: 7th, September\n",
      "Record Time: 8th, September\n",
      "Historian: Self\n",
      "Hospital Name: Bridgewater General Hospital\n",
      "\n",
      "**Chief Complaint:**\n",
      "Persistent joint pain and morning stiffness for 6 months\n",
      "\n",
      "**Present Illness:**\n",
      "Onset: The symptoms began insidiously 6 months ago, initially noticed while working at a construction site. Gradual onset with morning stiffness in the fingers and wrists.\n",
      "Main Symptoms: Morning stiffness, arthritis affecting hands, feet, wrists, ankles, and temporomandibular joints. Pain characterized as dull and persistent, worsens with activity and improves with rest.\n",
      "Accompanying Symptoms: Joint deformities in the hands, fatigue, intermittent fever, and weight loss of approximately 5 kg over the past few months.\n",
      "Diagnosis and Treatment History: Previously consulted a primary care physician and was prescribed NSAIDs which provided partial relief. No hospital admissions or invasive procedures performed prior to this episode.\n",
      "General Condition Changes: Reports feeling fatigued, difficulty sleeping due to pain, decreased appetite, and frequent urination. No significant changes in bowel habits.\n",
      "\n",
      "**Past History:**\n",
      "General Health Condition: Generally healthy with no chronic conditions.\n",
      "Disease History: No previous history of rheumatic diseases or chronic illnesses.\n",
      "Infectious Disease History: No significant infectious diseases.\n",
      "Immunization History: Up-to-date with routine immunizations.\n",
      "Surgery and Trauma History: Appendectomy at age 30, no significant traumas reported.\n",
      "Blood Transfusion History: No history of blood transfusions.\n",
      "Allergy History: Allergic to penicillin.\n",
      "\n",
      "**Personal History:**\n",
      "Birthplace: Bridgewater\n",
      "Residence: 22, Sunnyvale street, Bridgewater\n",
      "Living Habits: Non-smoker, occasional alcohol consumption, balanced diet.\n",
      "Occupation and Working Conditions: Construction worker, physically demanding job, exposed to heavy lifting and repetitive movements.\n",
      "Exposure History: No known exposure to industrial toxins, dust, or radioactive substances.\n",
      "Travel History: No recent travel outside the city.\n",
      "\n",
      "**Marital and Family History:**\n",
      "Marital Status: Married\n",
      "Marriage Age: 25\n",
      "Spouse's Health Condition: Healthy\n",
      "Children's Condition: Two children, both healthy.\n",
      "Family History: No known family history of rheumatoid arthritis or other autoimmune diseases. Parents are alive and healthy, no significant health issues reported in siblings.\n",
      "\n",
      "**Physical Examination:**\n",
      "General Condition:\n",
      "- Temperature: 37.2°C\n",
      "- Pulse: 78 bpm\n",
      "- Respiration: 18 breaths/min\n",
      "- Blood Pressure: 130/85 mmHg\n",
      "\n",
      "Systematic Examination:\n",
      "- Skin: No rashes or lesions.\n",
      "- Mucous Membranes: Normal, moist.\n",
      "- Lymph Nodes: No lymphadenopathy.\n",
      "- Head and Organs: Normal cephalic, no abnormalities.\n",
      "- Neck: No masses or thyromegaly.\n",
      "- Chest: Clear breath sounds, regular heart rhythm, no murmurs.\n",
      "- Abdomen: Soft, non-tender, no organomegaly.\n",
      "- Rectum and Anus: Normal, no hemorrhoids.\n",
      "- External Genitalia: Normal for age.\n",
      "- Spine: No deformities.\n",
      "- Limbs: Swelling and tenderness in wrists and metacarpophalangeal joints.\n",
      "- Nervous System: No focal deficits.\n",
      "\n",
      "**Specialist Examination:**\n",
      "Orthopedic and rheumatologic assessment showing positive rheumatoid factor and anti-CCP antibodies.\n",
      "\n",
      "**Auxiliary Examination:**\n",
      "MRI of hands and feet showing synovitis and erosions, X-rays with evidence of juxta-articular osteoporosis.\n",
      "\n",
      "**Preliminary Diagnosis:**\n",
      "Rheumatoid Arthritis\n",
      "\n",
      "**Diagnostic Basis:**\n",
      "Chronic symptoms of morning stiffness and joint pain, positive rheumatoid factor and anti-CCP antibodies, imaging showing synovitis and erosions.\n",
      "\n",
      "**Differential Diagnosis:**\n",
      "- Ankylosing spondylitis ruled out due to lack of sacroiliac joint involvement.\n",
      "- Osteoarthritis ruled out due to inflammatory nature of arthritis.\n",
      "- Gout ruled out due to negative urate crystals.\n",
      "- Psoriatic arthritis ruled out due to absence of psoriatic lesions.\n",
      "\n",
      "**Admission Records:**\n",
      "Physician's Signature: Dr. A. Smith\n",
      "\n",
      "**Post-Admission Course Records:**\n",
      "First Course Record: Within the first 8 hours, patient assessed for severity of symptoms and baseline workup completed. Initiation of DMARDs, specifically Methotrexate. NSAIDs continued for pain management.\n",
      "Daily Course Records: Noted improvement in pain with continued medication, regular monitoring of liver function tests due to Methotrexate.\n",
      "Senior Physician Rounds Records: Weekly rounds by senior physician confirming treatment plan, slight adjustments in DMARDs dosage.\n",
      "Difficult Case Discussion Records: Multidisciplinary discussion involving rheumatology, orthopedics, and physical therapy for long-term management plan.\n",
      "Handover Records: N/A\n",
      "Transfer Records: N/A\n",
      "Stage Summary: Patient showing moderate improvement, less morning stiffness, and slightly better joint mobility.\n",
      "Emergency Records: N/A\n",
      "Invasive Procedure Records: N/A\n",
      "Consultation Records: Rheumatology and physiotherapy consultations documented.\n",
      "Discharge Records: Patient to be discharged with outpatient follow-up in rheumatology clinic. Instructions on medication adherence and physical therapy.\n",
      "Critically Ill Patient Care Records: N/A\n",
      "\n",
      "**Medical Orders:**\n",
      "Long-term Orders: Methotrexate 15mg orally once weekly, Folic Acid 1mg daily, Naproxen 500mg twice daily as needed for pain.\n",
      "Temporary Orders: Liver function tests every 2 weeks, CBC with differential every month.\n",
      "\n",
      "**Auxiliary Examination Reports:**\n",
      "- Rheumatoid factor: positive\n",
      "- Anti-CCP: positive\n",
      "- ESR: elevated\n",
      "- CRP: elevated.\n",
      "\n",
      "**Temperature Chart:**\n",
      "Temperature stable around 37.2°C, pulse stable, blood pressure within normal limits.\n",
      "\n",
      "**Blood Transfusion Consent:**\n",
      "N/A\n",
      "\n",
      "**Special Examination Consent:**\n",
      "Consent obtained for MRI and X-rays.\n",
      "\n",
      "**Critical Condition Notice:**\n",
      "N/A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relevant_docs = []\n",
    "for doc, score in retrieved_docs:\n",
    "    content = doc.page_content\n",
    "    # Check if the document contains relevant keywords\n",
    "    if \"Bridgewater General Hospital\" in content and \"J. Reyes\" in content:\n",
    "        relevant_docs.append((doc.id, score, content))\n",
    "\n",
    "# Print the relevant documents ID, L2 distance, and content\n",
    "if relevant_docs:\n",
    "    for doc_id, score, content in relevant_docs:\n",
    "        print(f\"Relevant Document Found - ID: {doc_id}, L2 Distance: {score}\")\n",
    "        print(f\"Content: {content}\\n\")\n",
    "else:\n",
    "    print(\"No relevant documents found in the top-3 retrieved documents.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vector Store Evaluation\n",
    "\n",
    "**4a) [4 points]** Now, we will search with each of the queries for the most relevant documents in the vector store, and calculate Recall@N with them and the assigned ground truth document IDs. To aggregate the results over all queries, we will calculate the mean. We will do this 3 times to and use a different value for $N$ each time: $N \\in \\{ 1, 3, 5, 25\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1 = 0.6650\n",
      "Recall@3 = 0.8150\n",
      "Recall@5 = 0.8600\n",
      "Recall@25 = 1.0000\n"
     ]
    }
   ],
   "source": [
    "N_values = [1, 3, 5, 25]\n",
    "\n",
    "results = {n: [] for n in N_values}\n",
    "total_recall = {n: 0 for n in N_values}\n",
    "\n",
    "for index, row in queries.iterrows():\n",
    "\n",
    "    retrieved_docs = vector_store.similarity_search(row['query'], k=max(N_values))\n",
    "\n",
    "    for n in N_values:\n",
    "        recall = recall_at_n(retrieved_docs, row['ground_truth_doc_ids'], n)\n",
    "        total_recall[n] += recall\n",
    "\n",
    "for n in N_values:\n",
    "    print(f'Recall@{n} = {total_recall[n] / len(queries):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4b) [2 points]** When looking at the four calculated Recall@N scores, what do you observe and how can you explain this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n",
    "The recall@N increases with the value of N, since a larger value of N allows a bigger search space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cross Encoder\n",
    "\n",
    "**5a) [3 points]** We want to use a cross encoder model to rerank the retrieved documents. Describe in 1-2 sentences how a new document order can be determined using a cross encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5b) [4 points]** Now again, we want to calculate Recall@N for all queries and the same $N$ as before. This time, we want to rerank the Top-25 retrieved documents using the cross encoder model `BAAI/bge-reranker-base`. Implement this using LangChain components and report the average Recall for $N \\in \\{ 1, 3, 5, 25\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_with_rerankings(queries, vector_store, N_values):\n",
    "    results = {n: [] for n in N_values}\n",
    "    total_recall = {n: 0 for n in N_values}\n",
    "\n",
    "    cross_encoder = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-base\")\n",
    "    compressor = CrossEncoderReranker(model=cross_encoder, top_n=25)\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor, base_retriever=vector_store.as_retriever()\n",
    "    )\n",
    "\n",
    "    for index, row in queries.iterrows():\n",
    "        query = row['query']\n",
    "        ground_truth = set(row['ground_truth_doc_ids'])\n",
    "\n",
    "        reranked_docs = compression_retriever.invoke(query)\n",
    "        for n in N_values:\n",
    "            recall = recall_at_n(reranked_docs, ground_truth, n)\n",
    "            total_recall[n] += recall\n",
    "\n",
    "    average_recalls = {}\n",
    "    for n in N_values:\n",
    "        average_recalls[n] = total_recall[n] / len(queries)\n",
    "        print(f'Recall@{n} with reranking = {average_recalls[n]:.4f}')\n",
    "\n",
    "    return average_recalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1 with reranking = 0.7300\n",
      "Recall@3 with reranking = 0.8450\n",
      "Recall@5 with reranking = 0.8450\n",
      "Recall@25 with reranking = 0.8450\n"
     ]
    }
   ],
   "source": [
    "average_recall = calculate_with_rerankings(queries, vector_store, N_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5c) [2 points]** What do you observe when you compare the Recall@N scores after reranking with the scores without reranking? Write 1-2 sentences about this and why this might happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "Reranking improves Recall@1, meaning the top result is more often relevant. Recall@3, @5, and @25 stay the same because reranking changes the order, not the retrieved documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generation\n",
    "\n",
    "**6a) [6 points]** After improving the retrieval part of the RAG system, we want to finally generate an answer for our query. Retrieve the most relevant document for query \"How much funding did HealthPro Innovations raise in February 2021?\" and print its ID. Then write the instruction message of a prompt to answer this query including all necessary elements before running it using your favourite LLM (ChatGPT GPT-4o, etc.). Please paste the answer from the model and indicate which model you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Document ID: 54\n"
     ]
    }
   ],
   "source": [
    "query='How much funding did HealthPro Innovations raise in February 2021?'\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(query, k=1)\n",
    "print(f\"Retrieved Document ID: {retrieved_docs[0].metadata['id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Prompt:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= f\"\"\"\n",
    "You are a medical expert. Please answer the following question based on the retrieved document:\n",
    "###### Document\n",
    "{retrieved_docs[0].page_content}\n",
    "###### Question\n",
    "{query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generated Answer:**\n",
    "\n",
    "HealthPro Innovations raised $150 million in funding in February 2021.\n",
    "\n",
    "**Used Model:**\n",
    "\n",
    "ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6b) [3 points]** We want to use in-context learning and provide the LLM one example of a possible answer. Use the same prompt and extend it, that it should follow this example answer: \"Yep, they sold a lot in that year. Over 50 million units as I can see — pretty big move, respect!\". Use the same model, create a fresh chat and run this new prompt. Highlight the changes in the prompt using **bold style** or <span style=\"color:red;\">color</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Prompt:**\n",
    "\n",
    "Same as above + <b>Use this sample answer: \n",
    "\"Yep, they sold a lot in that year. Over 50 million units as I can see — pretty big move, respect!\"</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generated Answer:**\n",
    "\n",
    "Yep, they raised a lot in that month. A solid $150 million in February 2021 — pretty big move, respect!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6c) [2 points]** Please check if the two answers are correct according to the document and how they differ. Does the model follow the example in the second prompt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer:**\n",
    "both are answered correctly according to the context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of AdvNLP Lab\n",
    "\n",
    "Please make sure all cells have been executed, save this completed notebook, and upload it to Moodle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
